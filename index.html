<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Amaya Dharmasiri</title>
  
  <meta name="author" content="Amaya Dharmasiri">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Amaya Dharmasiri</name>
              </p>
              <p>
                I am a Research Assistant in Mohammad Bin Zayed University of Artificial Intelligence <a href="https://mbzuai.ac.ae/">(MBZUAI)</a> in the United Arab Emirates advised by <a href="https://salman-h-khan.github.io/">Dr. Salman H Khan</a>, of MBZUAI and <a href="https://research.google/people/106837/">Dr. Sadeep Jayasumana</a> of Google Research. My current research is on vision-language models for long-tail visual recognition.
              </p>
              <p>
                I did my undergraduate studies at <a href="https://uom.lk/">University of Moratuwa</a>, Sri Lanka, where I completed my bachelors thesis on Learning representations for 3D pointclouds and semantic manipulation of 3D pointcloud objects. The thesis was advised by <a href="https://ranga.staff.uom.lk/">Dr. Ranga Rodrigo</a> and <a href="https://scholar.google.com/citations?user=V-YM7ecAAAAJ&hl=en">Dr. Kanchana Thilakarathna.</a>
              </p>
              <p>
                Previously, I interned as a visiting student researcher at the <a href="https://www.sydney.edu.au/engineering/schools/school-of-computer-science.html">School of Computer Science</a>, University of Sydney, Australia.
              </p>
              <p>
                My broader research interests are in vision-language models, multimodal learning, and self-supervised learning.
              </p>
              <p style="text-align:center">
                <a href="mailto:minikiraniamaya@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Amaya_Dharmasiri_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.ch/citations?user=a1MvT1AAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/Amaya_Dharmasir">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/theamaya">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Amaya_Dharmasiri.jpg"><img style="width:75%;max-width:75%" alt="profile photo" src="images/Amaya_Dharmasiri.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <h2>News</h2>
            <ul>
                <li><b>October 2022</b>: Presented <a href="https://arxiv.org/pdf/2211.09770.pdf">our research</a> at <a href="https://learn3dg.github.io/">Learning to Generate 3D objects and Scenes</a> ECCV2022 workshop
                <li><b>July 2022</b>: I started working as a Research Assistant in <a href="https://mbzuai.ac.ae/">MBZUAI</a>
                <li><b>March 2022</b>: One <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Afham_CrossPoint_Self-Supervised_Cross-Modal_Contrastive_Learning_for_3D_Point_Cloud_Understanding_CVPR_2022_paper.pdf">paper</a> accepted to CVPR2022
                <li><b>September 2021</b>: Presented our <a href="https://dl.acm.org/doi/10.1145/3458306.3461000">research</a> at <a href="https://nossdav.org/2021/">NOSSDAV 2021</a> at <a href="https://2021.acmmmsys.org/">ACM MMSys</a>
                <li><b>June 2021</b>: Joined <a href="https://veracityai.com/en/">VeracityAI</a> as Associate Machine Learning Engineer
                <li><b>October 2020</b>: Joined <a href="https://www.sydney.edu.au/engineering/schools/school-of-computer-science.html">School of Computer Science</a> - USYD as visiting student researcher
            </ul>


        <h2>Research</h2>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/3dlatnav.png" alt="3dLatNav" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>3DLatNav: Navigating generative latent spaces for semantic aware 3D object manipulation</papertitle>
              <br>
              <strong>Amaya Dharmasiri</strong>,
              <a href="https://dkkim93.github.io/", target="_blank">Dinithi Dissanayake</a>,
              <a href="https://scholar.google.com/citations?user=PK7UzAwAAAAJ&hl=en" target="_blank">Isuru Dissanayake</a>,
              <a href="http://www.mit.edu/~miaoliu/", target="_blank">Mohamed Afham</a>,
              <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-gtesauro" target="_blank">Ranga Rodrigo</a>,
              <a href="https://scholar.google.com/citations?user=gX7rSCcAAAAJ&hl=en", target="_blank">Kanchana Thilakarathna</a>
              <br>
              <em>Learning to Generate 3D Objects and Scenes - ECCV 2022 Workshop</em>
              <br>
              <a href="https://arxiv.org/abs/2109.09876", target="_blank">Paper</a> /
              <a href="https://github.com/cradol/cradol", target="_blank">Code</a>
              <a href="https://sites.google.com/view/cradol/home", target="_blank">Video</a>
              <p></p>
              <p></p>
              <p>
              Developed a point cloud autoencoder architecture to apply controllable transformations to 3D objects via latent space manipulations while preserving perceptual quality of 3D objects and their intended utility in Mixed Reality applications.
              </p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crosspoint.png" alt="crosspoint" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding</papertitle>
              <br>
              <a href="https://dkkim93.github.io/", target="_blank">Mohamed Afham</a>,
              <a href="https://scholar.google.com/citations?user=PK7UzAwAAAAJ&hl=en" target="_blank">Isuru Dissanayake</a>,
              <a href="http://www.mit.edu/~miaoliu/", target="_blank">Dinithi Dissanayake</a>,
              <strong>Amaya Dharmasiri</strong>,
              <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-gtesauro" target="_blank">Kanchana Thilakarathna</a>,
              <a href="https://scholar.google.com/citations?user=gX7rSCcAAAAJ&hl=en", target="_blank">Ranga Rodrigo</a>
              <br>
              <em>CVPR 2022</em>
              <br>
              <a href="https://arxiv.org/abs/2109.09876", target="_blank">Paper</a> /
              <a href="https://github.com/cradol/cradol", target="_blank">Code</a>
              <a href="https://sites.google.com/view/cradol/home", target="_blank">Video</a>
              <p></p>
              <p></p>
              <p>
              Introduced a joint learning objective encapsulating intra-modal correspondence within point cloud modality and cross-modal correspondence between point cloud and 2D image modalities, leveraging contrastive learning.
              Produced state-of-the-art performance in downstream tasks; 3D object classification, few-shot object classification and 3D object part segmentation.
              </p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/spatial.png" alt="spatial" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>User configurable 3D object regeneration for spatial privacy</papertitle>
              <br>

              <a href="https://dkkim93.github.io/", target="_blank">Arpit Nama</a>,
              <strong>Marwa Abdulhai</strong>,
              <a href="http://www.mit.edu/~miaoliu/", target="_blank">Kanchana Thilakarathna</a>,
              <a href="https://scholar.google.com/citations?user=PK7UzAwAAAAJ&hl=en" target="_blank">Albert Y. Zomaya</a>,
              <a href="https://scholar.google.com/citations?user=BCbAD0UAAAAJ&hl=en" target="_blank">Jaybie Agullo de Guzman</a>
              <br>
              <em>Arxiv Preprint</em>
              <br>
              <a href="https://arxiv.org/pdf/2011.00382.pdf", target="_blank">Paper</a>
              <p></p>
              <p></p>
              <p>
                Proposed a privacy-preserving encoding for 3D point cloud objects with a continuous privilege spectrum for user-controllability of object privacy in mixed-reality applications.
              Evaluated the performance of the encoding against simulated object reidentification attacks using state-of-the-art point cloud classifiers.
              </p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/viewport.png" alt="viewport" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Viewport-aware dynamic 360-degree video segment categorization</papertitle>
              <br>
              <strong>Amaya Dharmasiri</strong>,
              <a href="http://www.mit.edu/~miaoliu/", target="_blank">Chamara Kattadige</a>,
              <a href="https://scholar.google.com/citations?user=PK7UzAwAAAAJ&hl=en" target="_blank">Vencent Zhang</a>,
              <a href="https://scholar.google.com/citations?user=BCbAD0UAAAAJ&hl=en" target="_blank">Kanchana Thilakarathna</a>
              <br>
              <em>NOSSDAV at ACM MMSys 2021</em>
              <br>
              <a href="https://www.youtube.com/watch?v=dkhRkWSc8Xw&feature=youtu.be">Paper</a> |
              <a href="https://abdulhaim.github.io/rss_2018/">Code</a>
              <br>
              <p></p>
              <p>
                Developed a dynamic categorisation framework for 360-degree video segments based on user viewport trends.
              This categorization is intended to support efficient caching and resource utilisation in tile-based 360 degree video streaming process.
              </p>
            </td>
          </tr>
        </tbody></table>


    <h2>Teaching</h2>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/embedded.jpg" alt="embedded" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>Visiting lecturer -  Open Course "Embedded Machine Learning for Edge Computing</papertitle>
              <br>
              Department of Electronic and Telecommunication Engineering, University of Moratuwa, Sri Lanka
              <br>
              Lectures - Introduction to Machine Learning
              September 2022
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>

    <h2>Experience</h2>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/veracity.png" alt="Veracity" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>VeracityAI, Colombo, Sri Lanka</papertitle>
              <br>
              Associate Machine Learning Engineer
              <br>
              June 2021 - February 2022
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/USYD.png" alt="USYD" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>School of Computer Science, University of Sydney, Australia</papertitle>
              <br>
              Visiting student researcher
              <br>
              October 2020 - April 2021
              Supervisor: <a href="https://scholar.google.com/citations?user=V-YM7ecAAAAJ&hl=en">Dr. Kanchana Thilakarathna.</a>
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>



    <h2>Education</h2>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/UOM.png" alt="UOM" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>University of Moratuwa</papertitle>
              <br>
              Bachelor's in Science (Engineering) specialized in Electronics and Telecommunications
              <br>
              August 2017 - July 2022
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>


      </td>
    </tr>
  </table>
  Template from <a href="https://jonbarron.info/">this website</a>.
</body>

</html>
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Amaya Dharmasiri</title>
  
  <meta name="author" content="Amaya Dharmasiri">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Amaya Dharmasiri</name>
              </p>
              <p>
                I am a first year PhD student in the <a href="https://visualai.princeton.edu/">(Princeton Visual AI lab)</a> advised by <a href="https://www.cs.princeton.edu/~olgarus/">Dr. Olga Russakovsky</a>.
              </p>
              <p>
                I did my undergraduate studies at <a href="https://uom.lk/">University of Moratuwa</a>, Sri Lanka, where I completed my bachelors thesis on Learning representations for 3D pointclouds and semantic manipulation of 3D pointcloud objects. The thesis was advised by <a href="https://ranga.staff.uom.lk/">Dr. Ranga Rodrigo</a> and <a href="https://scholar.google.com/citations?user=V-YM7ecAAAAJ&hl=en">Dr. Kanchana Thilakarathna.</a>
              </p>
              <p>
                Previously, I interned as a visiting student researcher at the <a href="https://www.sydney.edu.au/engineering/schools/school-of-computer-science.html">School of Computer Science</a>, University of Sydney. Later I worked as a research assistant in Mohammad Bin Zayed University of Artificial Intelligence <a href="https://mbzuai.ac.ae/">(MBZUAI)</a> in the United Arab Emirates advised by <a href="https://salman-h-khan.github.io/">Dr. Salman H Khan</a>, of MBZUAI and <a href="https://research.google/people/106837/">Dr. Sadeep Jayasumana</a> of Google Research.
              </p>
              <p>
                My broader research interests are in vision-language models, multimodal learning, and self-supervised learning.
              </p>
              <p style="text-align:center">
                <a href="mailto:minikiraniamaya@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Amaya_Dharmasiri_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.ch/citations?user=a1MvT1AAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/Amaya_Dharmasir">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/theamaya">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Amaya_Dharmasiri.jpg"><img style="width:75%;max-width:75%" alt="profile photo" src="images/Amaya_Dharmasiri.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <h2>News</h2>
            <ul>
                <li><b>September 2023</b>: Joined Princeton University as a PhD student in the Department of Computer Science.
                <li><b>December 2022</b>: Graduated with BSc. Electronic and Telecommuication Engineering (Hone) from University of Moratuwa with the award for <a href="https://ent.uom.lk/2023/01/16/convocation-award-winners-2022/">"Most Outstanding Graduand of 2022".</a>
                <li><b>October 2022</b>: Presented <a href="https://arxiv.org/pdf/2211.09770.pdf">our research</a> at <a href="https://learn3dg.github.io/">Learning to Generate 3D objects and Scenes</a> ECCV2022 workshop
                <li><b>July 2022</b>: I started working as a Research Assistant in <a href="https://mbzuai.ac.ae/">MBZUAI</a>
                <li><b>March 2022</b>: One <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Afham_CrossPoint_Self-Supervised_Cross-Modal_Contrastive_Learning_for_3D_Point_Cloud_Understanding_CVPR_2022_paper.pdf">paper</a> accepted to CVPR2022
                <li><b>September 2021</b>: Presented our <a href="https://dl.acm.org/doi/10.1145/3458306.3461000">research</a> at <a href="https://nossdav.org/2021/">NOSSDAV 2021</a> at <a href="https://2021.acmmmsys.org/">ACM MMSys</a>
                <li><b>June 2021</b>: Joined <a href="https://veracityai.com/en/">VeracityAI</a> as Associate Machine Learning Engineer
                <li><b>October 2020</b>: Joined <a href="https://www.sydney.edu.au/engineering/schools/school-of-computer-science.html">School of Computer Science</a> - USYD as visiting student researcher
            </ul>


        <h2>Research</h2>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/3dlatnav.png" alt="3dLatNav" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>3DLatNav: Navigating generative latent spaces for semantic aware 3D object manipulation</papertitle>
              <br>
              <strong>Amaya Dharmasiri</strong>,
              <a href="https://www.linkedin.com/in/dinithipurna/?originalSubdomain=lk", target="_blank">Dinithi Dissanayake</a>,
              Isuru Dissanayake,
              <a href="https://mohamedafham.github.io/", target="_blank">Mohamed Afham</a>,
              <a href="https://ranga.staff.uom.lk/" target="_blank">Ranga Rodrigo</a>,
              <a href="https://scholar.google.com/citations?user=V-YM7ecAAAAJ&hl=en", target="_blank">Kanchana Thilakarathna</a>
              <br>
              <em><a href="https://learn3dg.github.io/#accepted">Learning to Generate 3D Objects and Scenes</a> - ECCV 2022 Workshop</em>
              <br>
              <a href="https://arxiv.org/pdf/2211.09770.pdf", target="_blank">Paper</a> /
              <a href="https://github.com/theamaya/3DLatNav", target="_blank">Code</a>
              <a href="https://drive.google.com/file/d/1-NMo44QMzLzYM2Mh7og2P3Xa8MgU8eyE/view", target="_blank">Video</a>
              <p></p>
              <p></p>
              <p>
              Developed a point cloud autoencoder architecture to apply controllable transformations to 3D objects via latent space manipulations while preserving perceptual quality of 3D objects and their intended utility in Mixed Reality applications.
              </p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crosspoint.png" alt="crosspoint" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding</papertitle>
              <br>
              <a href="https://mohamedafham.github.io/", target="_blank">Mohamed Afham</a>,
              Isuru Dissanayake,
              <a href="https://www.linkedin.com/in/dinithipurna/?originalSubdomain=lk", target="_blank">Dinithi Dissanayake</a>,
              <strong>Amaya Dharmasiri</strong>,
              <a href="https://scholar.google.com/citations?user=V-YM7ecAAAAJ&hl=en" target="_blank">Kanchana Thilakarathna</a>,
              <a href="https://ranga.staff.uom.lk/", target="_blank">Ranga Rodrigo</a>
              <br>
              <em>CVPR 2022</em>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Afham_CrossPoint_Self-Supervised_Cross-Modal_Contrastive_Learning_for_3D_Point_Cloud_Understanding_CVPR_2022_paper.pdf", target="_blank">Paper</a> /
              <a href="https://github.com/MohamedAfham/CrossPoint", target="_blank">Code</a>
              <a href="https://mohamedafham.github.io/CrossPoint/", target="_blank">Project page</a>
              <p></p>
              <p></p>
              <p>
              Introduced a joint learning objective encapsulating intra-modal correspondence within point cloud modality and cross-modal correspondence between point cloud and 2D image modalities, leveraging contrastive learning.
              Produced state-of-the-art performance in downstream tasks; 3D object classification, few-shot object classification and 3D object part segmentation.
              </p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/spatial.png" alt="spatial" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>User configurable 3D object regeneration for spatial privacy</papertitle>
              <br>

              <a href="https://www.researchgate.net/profile/Arpit_Nama", target="_blank">Arpit Nama</a>,
              <strong>Amaya Dharmasiri</strong>,
              <a href="https://scholar.google.com/citations?user=V-YM7ecAAAAJ&hl=en", target="_blank">Kanchana Thilakarathna</a>,
              <a href="https://scholar.google.com/citations?user=ak35bjgAAAAJ&hl=en" target="_blank">Albert Y. Zomaya</a>,
              <a href="https://www.researchgate.net/profile/Jaybie-De-Guzman" target="_blank">Jaybie Agullo de Guzman</a>
              <br>
              <em>Arxiv Preprint</em>
              <br>
              <a href="https://arxiv.org/pdf/2108.08273.pdf", target="_blank">Paper</a>
              <p></p>
              <p></p>
              <p>
                Proposed a privacy-preserving encoding for 3D point cloud objects with a continuous privilege spectrum for user-controllability of object privacy in mixed-reality applications.
              Evaluated the performance of the encoding against simulated object reidentification attacks using state-of-the-art point cloud classifiers.
              </p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/viewport.png" alt="viewport" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Viewport-aware dynamic 360-degree video segment categorization</papertitle>
              <br>
              <strong>Amaya Dharmasiri</strong>,
              <a href="https://scholar.google.com/citations?user=DayFwIcAAAAJ&hl=en", target="_blank">Chamara Kattadige</a>,
              Vencent Zhang,
              <a href="https://scholar.google.com/citations?user=V-YM7ecAAAAJ&hl=en" target="_blank">Kanchana Thilakarathna</a>
              <br>
              <em>NOSSDAV at ACM MMSys 2021</em>
              <br>
              <a href="https://dl.acm.org/doi/10.1145/3458306.3461000">Paper</a> |
              <a href="https://github.com/theamaya/Viewport-Aware-Dynamic-360-Video-Segment-Categorization">Code</a> |
              <a href="https://youtu.be/M8ZGkTgw8HU">Video</a>
              <br>
              <p></p>
              <p>
                Developed a dynamic categorisation framework for 360-degree video segments based on user viewport trends.
              This categorization is intended to support efficient caching and resource utilisation in tile-based 360 degree video streaming process.
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/stereo.png" alt="stereo" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Multimodal Late-Fusion for stereo Object Detection</papertitle>
              <br>
              <strong>Amaya Dharmasiri</strong>,
              <a href="https://scholar.google.com/citations?user=NjG1z50AAAAJ&hl=en" target="_blank">Ramith Hettiarachchi</a>
              Isuru Dissanayake,
              <a href="https://scholar.google.com/citations?user=qYLOPxoAAAAJ&hl=en" target="_blank">Sadeep Jayasumana</a>
              <br>
              <a href="data/Combining_Object_Detections.pdf">Technical Report</a>
              <br>
              <p></p>
              <p>
                We investigate different aspects of combining object detections between pairs of stereo images for a given object detector to improve the overall precision and recall.
                We also deduce a theoretical maximum for this improvement based on the correlation between the stereo pairs.
              </p>
            </td>
          </tr>
        </tbody></table>


    <h2>Teaching</h2>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/embedded.jpg" alt="embedded" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>Visiting lecturer -  Open Course in "Embedded Machine Learning for Edge Computing"</papertitle>
              <br>
              Department of Electronic and Telecommunication Engineering, University of Moratuwa, Sri Lanka
              <br>
              <a href="data/Introduction_to_Machine_Learning.pdf">Lectures - Introduction to Machine Learning</a>
              <br>
              September 2022
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>

    <h2>Experience</h2>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mbzuai.png" alt="MBZUAI" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>Mohamed Bin Zayed University of Artificial Intelligence, Abu Dhabi, United Arab Emirates</papertitle>
              <br>
              Research Assistant
              <br>
              July 2022 - Present
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/veracity.png" alt="Veracity" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>VeracityAI, Colombo, Sri Lanka</papertitle>
              <br>
              Associate Machine Learning Engineer
              <br>
              June 2021 - February 2022
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/USYD.png" alt="USYD" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>School of Computer Science, University of Sydney, Australia</papertitle>
              <br>
              Visiting student researcher
              <br>
              October 2020 - April 2021
              Supervisor: <a href="https://scholar.google.com/citations?user=V-YM7ecAAAAJ&hl=en">Dr. Kanchana Thilakarathna.</a>
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>



    <h2>Education</h2>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/University-of-Princeton-Emblem.png" alt="Princeton" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>Princeton University</papertitle>
              <br>
              Ph.D. in Computer Science
              <br>
              September 2023 - Present
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/UOM.png" alt="UOM" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
               <papertitle>University of Moratuwa</papertitle>
              <br>
              Bachelor's in Science (Engineering) specialized in Electronics and Telecommunications
              <br>
              August 2017 - July 2022
              <p></p>
              <p></p>
            </td>
          </tr>
            </td>
          </tr>
        </tbody></table>




      </td>
    </tr>
  </table>
  Template from <a href="https://jonbarron.info/">this website</a>.
</body>

</html>